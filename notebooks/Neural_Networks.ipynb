{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks\n",
    "\n",
    "A neural network is a nested function of it's layers.\n",
    "\n",
    "For example, this is a 3 layered neural network's function which returns a scalar, vector or matrix, depending on the problem:\n",
    "\n",
    "$$\n",
    "y = f_{NN}(\\boldsymbol{X}) = f_{3}(\\boldsymbol{f_{2}}(\\boldsymbol{f_{1}}(\\boldsymbol{X})))\n",
    "$$\n",
    "\n",
    "Where `f1` and `f2` are returning a vector. More generaly for the `l`th inner layer:\n",
    "\n",
    "$$\n",
    "\\boldsymbol{f_{l}}(\\boldsymbol{Z}) = \\boldsymbol{actf_{l}}(\\boldsymbol{W_{l}}\\boldsymbol{Z} + \\boldsymbol{b_{l}})\n",
    "$$\n",
    "\n",
    "Where `actf` is the activation function, `W` is the matrix of weights and `b` is a vector.\n",
    "\n",
    "Here is the code for a simple multilayer perceptron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0  loss: 0.3254\n",
      "epoch: 100  loss: 0.2203\n",
      "epoch: 200  loss: 0.1939\n",
      "epoch: 300  loss: 0.1717\n",
      "epoch: 400  loss: 0.1516\n",
      "epoch: 500  loss: 0.1332\n",
      "epoch: 600  loss: 0.1164\n",
      "epoch: 700  loss: 0.1012\n",
      "epoch: 800  loss: 0.0876\n",
      "epoch: 900  loss: 0.0756\n",
      "\n",
      "Prediction:\t [0. 1. 1. 0.]\n",
      "Target:\t\t [0 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "xor_data = np.array([\n",
    "    [0, 0, 1],\n",
    "    [0, 1, 1],\n",
    "    [1, 0, 1],\n",
    "    [1, 1, 1]\n",
    "])\n",
    "xor_target = np.array([\n",
    "    [0],\n",
    "    [1],\n",
    "    [1],\n",
    "    [0]\n",
    "])\n",
    "\n",
    "epochs = 1000\n",
    "alpha = 0.1  # learning rate\n",
    "hidden_layer_size = 10\n",
    "X = xor_data\n",
    "y = xor_target\n",
    "\n",
    "# layers\n",
    "W = [  \n",
    "    2*np.random.random((X.shape[1], hidden_layer_size)) - 1,\n",
    "    2*np.random.random((hidden_layer_size, y.shape[1])) - 1\n",
    "]\n",
    "b = [\n",
    "    2*np.random.random((X.shape[0], hidden_layer_size)) - 1,\n",
    "    2*np.random.random() - 1\n",
    "]\n",
    "\n",
    "# activation function\n",
    "def actf(Z: np.ndarray, derivate=False) -> np.ndarray:\n",
    "    if derivate:\n",
    "        return Z*(1 - Z)\n",
    "    return 1 / (1 + np.exp(-Z))\n",
    "\n",
    "\n",
    "# start the algorithm\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    # feed forward\n",
    "    h = actf(np.dot(X, W[0]) + b[0])\n",
    "    y_hat = actf(np.dot(h, W[1]) + b[1])\n",
    "\n",
    "    # backpropagation of errors\n",
    "    dW1 = (y - y_hat)*actf(y_hat, derivate=True)\n",
    "    dW0 = np.dot(dW1, W[1].T)*actf(h, derivate=True)\n",
    "    W[1] += alpha*np.dot(h.T, dW1)\n",
    "    W[0] += alpha*np.dot(X.T, dW0)\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        print('epoch:', epoch, ' loss:', round(((y - y_hat)**2).mean(), 4))\n",
    "\n",
    "print()\n",
    "prediction = y_hat.T[0]\n",
    "prediction[prediction > 0.5] = 1\n",
    "prediction[prediction <= 0.5] = 0\n",
    "\n",
    "print('Prediction:\\t', prediction)\n",
    "print('Target:\\t\\t', y.T[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
